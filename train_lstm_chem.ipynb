{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfU59FXOrEQ5"
   },
   "source": [
    "# MOUNT GOOGLE Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L60qoWhx8u1N"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30b2ZTK42K-j"
   },
   "outputs": [],
   "source": [
    "!pip3 install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQhJM4IrnbI6"
   },
   "outputs": [],
   "source": [
    "model_name='lstm_chem' # @param\n",
    "iden=str(model_name).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "filUtUgerXRq"
   },
   "source": [
    "# Change your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3aN7xhNqgOn"
   },
   "outputs": [],
   "source": [
    " cd /content/gdrive/My\\ Drive/pySMD/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfrQJj1Gqxx6"
   },
   "source": [
    "# TPU CHECK\n",
    "The model trains faster in TPU (approximately 17 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEkaY0jqfP5T"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime;')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocr7RR6jsBXG"
   },
   "source": [
    "# FIXED PARAMETERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SynPRxh2o0m9"
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os \n",
    "\n",
    "BUCKET='tfalldata' # @param\n",
    "TFIDEN='tfrecSMDsample'  # @param\n",
    "SMI_MAXLEN=77 # @param\n",
    "TOKENIZER_TABLE_LEN=47 # @param\n",
    "DATA_DIM=(SMI_MAXLEN+1,TOKENIZER_TABLE_LEN)\n",
    "BATCH_SIZE=1024 # @param\n",
    "BUFFER_SIZE=2048 # @param\n",
    "TRAIN_DATA=10240*35 # @param\n",
    "EVAL_DATA=10240*9 # @param\n",
    "\n",
    "EPOCHS=50 # @param\n",
    "TOTAL_DATA=TRAIN_DATA+EVAL_DATA\n",
    "STEPS_PER_EPOCH = TOTAL_DATA//BATCH_SIZE\n",
    "EVAL_STEPS      = EVAL_DATA//BATCH_SIZE\n",
    "GCS_PATH='gs://{}/{}'.format(BUCKET,TFIDEN)\n",
    "print(GCS_PATH)\n",
    "\n",
    "WEIGHT_PATH=os.path.join(os.getcwd(),'weights','{}.h5'.format(iden))\n",
    "if os.path.exists(WEIGHT_PATH):\n",
    "  print('FOUND PRETRAINED WEIGHTS')\n",
    "  LOAD_WEIGHTS=True \n",
    "else:\n",
    "  print('NO PRETRAINED WEIGHTS FOUND')\n",
    "  LOAD_WEIGHTS=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jATm2xu_sKVK"
   },
   "source": [
    "# Dataset wrapper with tf.data api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuT6HPWV2vLb"
   },
   "outputs": [],
   "source": [
    "from coreLib.utils import data_input_fn\n",
    "eval_ds = data_input_fn(GCS_PATH,'Train',DATA_DIM,BATCH_SIZE,BUFFER_SIZE)\n",
    "train_ds =data_input_fn(GCS_PATH,'Eval',DATA_DIM,BATCH_SIZE,BUFFER_SIZE)\n",
    "for x,y in eval_ds.take(1):\n",
    "  print(x.shape)\n",
    "  print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXowKzxMsd8W"
   },
   "source": [
    "# model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwHcjhf8qyZg"
   },
   "outputs": [],
   "source": [
    "from coreLib.models import LSTM_Chem\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "  model = LSTM_Chem(256,TOKENIZER_TABLE_LEN)\n",
    "  model.compile(optimizer=\"Adam\",\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"])\n",
    "  if LOAD_WEIGHTS:\n",
    "    model.load_weights(WEIGHT_PATH)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjnppw11ssA_"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCW_-2verNfJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# reduces learning rate on plateau\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,\n",
    "                                                  cooldown= 10,\n",
    "                                                  patience=10,\n",
    "                                                  verbose =1,\n",
    "                                                  min_lr=0.1e-5)\n",
    "\n",
    "mode_autosave = tf.keras.callbacks.ModelCheckpoint(WEIGHT_PATH,\n",
    "                                                  save_best_only=True, \n",
    "                                                  verbose=1, \n",
    "                                                  period =10)\n",
    "\n",
    "# stop learining as metric on validatopn stop increasing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=15,verbose=1, mode = 'auto') \n",
    "\n",
    "callbacks = [mode_autosave, lr_reducer,early_stopping ]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_data=eval_ds,\n",
    "                    validation_steps=EVAL_STEPS,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# save model\n",
    "#Final_weights=os.path.join(os.getcwd(),'lstm_chem_final.h5')\n",
    "#model.save_weights(Final_weights)\n",
    "\n",
    "def plot_history(history):\n",
    "  \"\"\"\n",
    "  Plots model training history \n",
    "  \"\"\"\n",
    "  fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "  ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "  ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "  ax_loss.legend()\n",
    "  ax_acc.plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n",
    "  ax_acc.plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "  ax_acc.legend()\n",
    "  plt.show()\n",
    "# show history\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_lstm_chem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
